#!/bin/bash
# =================================================================================
#    This file is part of pipeVFX.
#
#    pipeVFX is a software system initally authored back in 2006 and currently
#    developed by Roberto Hradec - https://bitbucket.org/robertohradec/pipevfx
#
#    pipeVFX is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Lesser General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    pipeVFX is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Lesser General Public License for more details.
#
#    You should have received a copy of the GNU Lesser General Public License
#    along with pipeVFX.  If not, see <http://www.gnu.org/licenses/>.
# =================================================================================#
# use this script to build all libraries used by pipeVFX, with all versions
#

CD=$(readlink -f $(dirname $BASH_SOURCE))/../../../

if [ "$STUDIO" == "" ] ; then
    export STUDIO=atomo
fi
export STUDIO

if [ "$PRE_CMD" != "" ] ; then
    export PRE_CMD
fi

# base image from centos used
#raw_image=centos:7.6.1810
raw_image=fedora:35

if [ "$IMAGE" == "centos" ] ; then
    raw_image=centos:7.6.1810
elif [ "$IMAGE" != "" ] ; then
    raw_image=$IMAGE
fi

# base image name for pipeVFX images
base=hradec/pipevfx

# the image name for the image that holds package files (our pkg cache image!)
pkg_image=${base}_pkgs:centos7

# a tag name so the build image pulls the latest always
pkg_image_tag=${base}_pkgs:centos7_latest

# the build image name!
#build_image=${base}_build:centos7
build_image=${base}_build:$(echo $raw_image | sed 's/://')

SHELL=1
PUSH=0
BUILD=0
while getopts hsbdupe: option ; do
    case "${option}"
    in
        h) export HELP=1;;
        s) export SHELL=1;;
        b) export SHELL=0;;
        d) export DEBUG="debug=1";;
        u) export UPLOAD=1;;
        p) export PKGS=1;;
        e) export EXTRA="${OPTARG}";;
        # v) EXTRA_VARS="${OPTARG}";;
    esac
done



if [ "$HELP" != "" ] ; then
    echo -e "\n$(basename $0) options:\n"
    echo -e "\t-h   : show this help"
    echo -e "\t-s   : run a shell in the docker build image, with pipeVFX initialized"
    echo -e "\t-b   : build libraries"
    echo -e "\t-d   : run the build in debug mode (show the build log)"
    echo -e "\t-e   : add extra attributes which will be passed to scons"
    echo -e "\t-v   : add extra environment variable which will be passed to the docker container that runs scons"
    echo -e "\t-u   : build and upload the build docker image"
    echo -e "\t-p   : build the package cache image and upload to docker hub"
    echo ''
else
    # copy docker init script to docker folder, so we keep the docker folder small and tidy!
    # cp $CD/pipeline/tools/scripts/pipevfx_docker_init.sh $CD/docker/run.sh

    if [ "$EXTRA_VARS" != "" ] ; then
        for e in $EXTRA_VARS ; do
            EXTRA_ENVS=" $EXTRA_ENVS -e $e "
        done
    fi

    latest_tag=$(echo $pkg_image | awk -F':' '{print $1}'):$(
        curl -L \
        https://registry.hub.docker.com/v1/repositories/"$(echo $pkg_image | awk -F: '{print $1}')"/tags  \
        | tr -d '[]" ' \
        | tr '}' '\n' \
        | awk -F: '{print $3}' \
        | grep -v latest \
        | sort -h | tail -1
    )
    if [ "$latest_tag" == "$(echo $pkg_image | awk -F':' '{print $1}'):" ] ; then
        latest_tag=$pkg_image
        previous_tag=$raw_image
    else
        if [ "$PKGS" == "1" ] ; then
            tmp=$latest_tag
            latest_tag=${pkg_image}_$(echo $latest_tag | awk -Fcentos7_ '{$2++;printf("%04d",$2)}')
            previous_tag=$tmp
        fi
    fi

    # try to pull pkg image from docker hub
    # docker pull $latest_tag
    # if [ $? != 0 ] ; then
    #     UPLOAD=1
    #     PKGS=1
    # fi
    # # try to pull build image from docker hub
    # docker pull $build_image
    # if [ $? != 0 ] ; then
    #     UPLOAD=1
    # fi

    if [ "$PKGS" == "1" ] ; then
        echo -e "\n\nusing pkg_image:$previous_tag \nto build new_tag:$latest_tag\n"
        # packages download
        docker pull $previous_tag
        docker image tag $previous_tag $pkg_image_tag
        docker build \
            -f $CD/docker/Dockerfile.pkgs \
            $CD/ \
            -t $latest_tag \
            --pull \
            --compress \
            --rm \
            --build-arg http="$http_proxy" \
            --build-arg https="$https_proxy" \
            --build-arg BASE_IMAGE="$previous_tag" \
            --build-arg PRE_CMD="$PRE_CMD" \
            --build-arg POS_CMD="$POS_CMD"

        if [ $? -ne 0 ] ; then
            echo ERROR!!
            exit -1
        fi
        docker image tag $latest_tag $pkg_image_tag
        exit 0
    fi

    # if no image in docker hub or we used -b to force a build, build it
    # and push it to docker hub!
    if [ "$UPLOAD" == "1" ] ; then
        # we have to push pkg cache tags first, since the dockerfile needs it. 
        docker push $latest_tag
        docker push $pkg_image_tag

        # build image!
        echo -e "\nbuilding image:$build_image using $raw_image as base.\npackage image:$latest_tag\n\n"
        docker build \
            -f $CD/docker/Dockerfile.build \
            $CD/ \
            -t $build_image \
            --pull \
            --compress \
            --rm \
            --build-arg http="$http_proxy" \
            --build-arg https="$https_proxy" \
            --build-arg PACKAGES="$latest_tag" \
            --build-arg BASE_IMAGE="$raw_image"

        if [ $? -ne 0 ] ; then
            echo ERROR!!
            exit -1
        fi
        # docker-squash --tmp-dir /var/lib/docker/squash_tmp/ $latest_tag || true
        # docker-squash --tmp-dir /var/lib/docker/squash_tmp/ $build_image || true
        docker push $build_image
        exit $?
    fi

    TI=" -ti "
    if [ "$TRAVIS" == "1" ] ; then
        TI="-t"
    else
        # use real apps folder if we have one!
        APPS_MOUNT=" -v $CD/apps:/$STUDIO/apps"
        if [ -e /$STUDIO/apps ] && [ "$TRAVIS" == "" ] ; then
            APPS_MOUNT=" -v $(readlink -f /$STUDIO/apps):/$STUDIO/apps "
        fi
        if [ -e /$STUDIO/jobs ] ; then
            APPS_MOUNT=" $APPS_MOUNT -v $(readlink -f /$STUDIO/jobs):/$STUDIO/jobs "
        fi
    fi

    # use wget proxy setup if it exists
    if [ -e $HOME/.wgetrc ] ; then
        APPS_MOUNT="$APPS_MOUNT -v $HOME/.wgetrc:/root/.wgetrc"
    fi

    X11=""
    if [ "$SHELL" == "1" ] ; then
        X11=" -v /tmp/.X0-lock:/tmp/.X0-lock:rw -v /tmp/.X11-unix:/tmp/.X11-unix:rw -e QT_X11_NO_MITSHM=1 -e DISPLAY -e XAUTHORITY  "
        # if [ "$(which nvidia-smi)" != "" ] ; then
        #     X11="$X11 --runtime=nvidia -e NVIDIA_DRIVER_CAPABILITIES=all "
        # fi

        # instead of using just nvidia custom runtime, we choosed to use the host systems
        # GL libraries, by mounting then to the docker image. This way, the docker
        # image will use libraries compatible with the host video driver, no matter
        # what video driver/manufacturer it is!
        # this seems to work fine with NVidia drivers on arch linux!
        # need more testing on other distros/video board setups.
        # this mode only works if we run the docker container with --privileged!
        extra_libs1=$(ldconfig -p | grep libGL | grep -v GLU |  grep x86 | awk  '{print $NF}' | while read p ; do [ "$p" != "" ] && pp=$(readlink -f $p) && echo -v $pp:/lib64/$(basename $p):ro ; done)
        if [ "$(which nvidia-smi 2>/dev/null)" != "" ] ; then
            extra_libs2=$(ldconfig -p | grep libnvidia | grep $(nvidia-smi | grep SMI | awk '{print $6}') | grep x86 | awk  '{print "-v "$NF":/lib64/"$1":ro"}')
            if [ -e /opt/cuda ] ; then
                extra_libs3=$(ldconfig -p | grep cuda | grep -v opt | grep x86 | awk  '{print "-v "$NF":/lib64/"$1":ro"}')
                extra_libs4=" -v /opt/cuda:/opt/cuda "
            fi
        fi
        X11=" $X11 $extra_libs1 $extra_libs2 $extra_libs3 $extra_libs4 "
        # X11=" $X11 --volume /run/dbus/system_bus_socket:/run/dbus/system_bus_socket "

        # and let X accept connections no matter what
        xhost + > /dev/null 2>&1
    fi

    LIB_FOLDER="$CD/pipeline/libs/"
    BUILD_FOLDER="$CD/pipeline/build/.build/"
    if [ "$CUSTOM_LIB_FOLDER" != "" ] ; then
        LIB_FOLDER="$(readlink -f $CUSTOM_LIB_FOLDER)"
        BUILD_FOLDER="$LIB_FOLDER/__BUILD__/"
    fi

    # create lib folder
    mkdir -p "$LIB_FOLDER"
    mkdir -p "$BUILD_FOLDER"

    # this one liner creates the _uid, _user, _gid and _group env vars, so we can
    # pass it on to the docker container.
    # as it uses the id command, it should work on any host distro that has id command
    eval $(echo $(for n in $(id) ; do echo $n | tr '()' ' ' | egrep 'gid|uid' ; done  | awk -F'=' '{print $2}') | awk '{print "export _uid="$1,"; export _user="$2,"; export _gid="$3,"; export _group="$4}')


    # now we can finally run a build!
    cmd="docker rm -f pipevfx_make >/dev/null 2>&1 ; \
        docker pull $build_image ; \
        docker run --rm $TI \
        -v $CD/docker/:/.docker/ \
        -v $CD/.github/:/.github/ \
        -v $CD/pipeline/tools/:/$STUDIO/pipeline/tools/ \
        -v $CD/pipeline/tags/:/$STUDIO/pipeline/tags/ \
        -v $LIB_FOLDER:/$STUDIO/pipeline/libs/ \
        -v $CD/pipeline/build/SConstruct:/$STUDIO/pipeline/build/SConstruct \
        -v $CD/pipeline/build/patches:/$STUDIO/pipeline/build/patches \
        -v $BUILD_FOLDER:/$STUDIO/pipeline/build/.build/ \
        --mount type=bind,source=$CD/pipeline/tools/scripts/pipevfx_docker_init.sh,target=/run.sh \
        -v $CD/.root:/$STUDIO/.root \
        -v $HOME:/home/$USER/ \
        $EXTRA_MOUNTS \
        $APPS_MOUNT \
        -e _UID=$_uid \
        -e _USER=$_user \
        -e _GID=$_gid \
        -e _GROUP=$_group \
        -e RUN_SHELL=$SHELL \
        -e EXTRA=\"$EXTRA\" \
        -e DEBUG=\"$DEBUG\" \
        -e DOCKER=\"$DOCKER\" \
        -e TRAVIS=\"$TRAVIS\" \
        -e http_proxy=\"$http_proxy\" \
        -e https_proxy=\"$https_proxy\" \
        -e STUDIO=\"$STUDIO\" \
        -e RAMDISK=\"$RAMDISK\" \
        $EXTRA_ENVS \
        -e MEMGB=\"$(grep MemTotal /proc/meminfo | awk '{print $(NF-1)}')\" \
        $X11 \
        --network=host \
        --privileged \
        --entrypoint /$STUDIO/pipeline/tools/scripts/pipevfx_docker_init.sh \
        $build_image "

        # -v $CD/pipeline/tools/scripts/pipevfx_docker_init.sh:/run.sh \
        # --entrypoint /bin/bash \
        # $build_image  -c \"mv /atomo /$STUDIO ; cp /run.sh /run.bak ; cat /run.bak | sed 's/atomo/$STUDIO/g' > /run.sh ; chmod a+x /run.sh ; /run.sh \" "

    # echo $cmd
    eval $cmd
fi
